{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Channels of the 1. image:\n",
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n",
      "Channels of the 2. image:\n",
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 254 250]\n",
      "  [255 254 249]\n",
      "  [255 255 247]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 254 250]\n",
      "  [255 254 247]\n",
      "  [255 254 247]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 254 249]\n",
      "  [255 254 247]\n",
      "  [255 254 245]]]\n",
      "Channels of the 3. image:\n",
      "[[[230 230 230]\n",
      "  [230 230 230]\n",
      "  [230 230 230]\n",
      "  ...\n",
      "  [230 230 230]\n",
      "  [230 230 230]\n",
      "  [230 230 230]]\n",
      "\n",
      " [[230 230 230]\n",
      "  [230 230 230]\n",
      "  [230 230 230]\n",
      "  ...\n",
      "  [230 230 230]\n",
      "  [230 230 230]\n",
      "  [230 230 230]]\n",
      "\n",
      " [[230 230 230]\n",
      "  [230 230 230]\n",
      "  [230 230 230]\n",
      "  ...\n",
      "  [230 230 230]\n",
      "  [230 230 230]\n",
      "  [230 230 230]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[230 230 230]\n",
      "  [230 230 230]\n",
      "  [230 230 230]\n",
      "  ...\n",
      "  [230 230 230]\n",
      "  [230 230 230]\n",
      "  [230 230 230]]\n",
      "\n",
      " [[230 230 230]\n",
      "  [230 230 230]\n",
      "  [230 230 230]\n",
      "  ...\n",
      "  [230 230 230]\n",
      "  [230 230 230]\n",
      "  [230 230 230]]\n",
      "\n",
      " [[230 230 230]\n",
      "  [230 230 230]\n",
      "  [230 230 230]\n",
      "  ...\n",
      "  [230 230 230]\n",
      "  [230 230 230]\n",
      "  [230 230 230]]]\n",
      "Channels of the 4. image:\n",
      "[[[249 255 255]\n",
      "  [255 254 255]\n",
      "  [255 250 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[251 255 255]\n",
      "  [252 255 255]\n",
      "  [253 254 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[252 255 255]\n",
      "  [249 255 255]\n",
      "  [247 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [254 254 254]\n",
      "  [254 254 254]\n",
      "  [254 254 254]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [254 254 254]\n",
      "  [254 254 254]\n",
      "  [254 254 254]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [254 254 254]\n",
      "  [254 254 254]\n",
      "  [254 254 254]]]\n",
      "Channels of the 5. image:\n",
      "[[[ 43 148  56]\n",
      "  [ 43 148  56]\n",
      "  [ 43 148  56]\n",
      "  ...\n",
      "  [ 44 144  54]\n",
      "  [ 44 149  56]\n",
      "  [ 42 148  50]]\n",
      "\n",
      " [[ 43 148  56]\n",
      "  [ 43 148  56]\n",
      "  [ 43 148  56]\n",
      "  ...\n",
      "  [ 41 149  63]\n",
      "  [ 40 149  60]\n",
      "  [ 43 148  55]]\n",
      "\n",
      " [[ 43 148  56]\n",
      "  [ 43 148  56]\n",
      "  [ 43 148  56]\n",
      "  ...\n",
      "  [ 39 149  62]\n",
      "  [ 40 145  60]\n",
      "  [ 46 146  56]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 46 146  56]\n",
      "  [ 40 145  60]\n",
      "  [ 39 149  62]\n",
      "  ...\n",
      "  [ 43 148  56]\n",
      "  [ 44 147  56]\n",
      "  [ 44 147  56]]\n",
      "\n",
      " [[ 43 148  55]\n",
      "  [ 40 149  60]\n",
      "  [ 43 148  63]\n",
      "  ...\n",
      "  [ 44 147  56]\n",
      "  [ 44 147  55]\n",
      "  [ 46 147  55]]\n",
      "\n",
      " [[ 42 148  50]\n",
      "  [ 44 149  56]\n",
      "  [ 44 144  54]\n",
      "  ...\n",
      "  [ 44 147  56]\n",
      "  [ 46 147  55]\n",
      "  [ 46 147  53]]]\n"
     ]
    }
   ],
   "source": [
    "#1.: reading images, displaying those and the RGB tensors of those\n",
    "%pylab \n",
    "import imageio #!!!code has to be run in order to display the images!!!  every picture will be displayed in a different window\n",
    "import matplotlib.pyplot as plt #the pics folder has to be put in the current working directory \n",
    "\n",
    "pics=[]  # the data of each picture will be stored in this list\n",
    "images=[] # the name of each picture will be stored in here\n",
    "for i in range(5):\n",
    "    exec(\"\"\"images.append('pic%d')\"\"\"%(i+1))\n",
    "index=0\n",
    "for image in images:\n",
    "    plt.figure()   #new figure has to be opened before reading a new image \n",
    "    exec(\"\"\"pics.append(imageio.imread('./pics/%s.jpg'))\"\"\"%image) # RGB channels are contained by an imageio.core.util.Image object,               \n",
    "    print('Channels of the %d. image:'%(index+1))                         \n",
    "    print(pics[index])\n",
    "    plt.imshow(pics[index]) # displaying the image\n",
    "    index+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average values:\n",
      "[[[206.4 228.6 210.2]\n",
      "  [207.6 228.4 210.2]\n",
      "  [207.6 227.6 210.2]\n",
      "  ...\n",
      "  [207.8 227.8 209.8]\n",
      "  [207.8 228.8 210.2]\n",
      "  [207.4 228.6 209. ]]\n",
      "\n",
      " [[206.8 228.6 210.2]\n",
      "  [207.  228.6 210.2]\n",
      "  [207.2 228.4 210.2]\n",
      "  ...\n",
      "  [207.2 228.8 211.6]\n",
      "  [207.  228.8 211. ]\n",
      "  [207.6 228.6 210. ]]\n",
      "\n",
      " [[207.  228.6 210.2]\n",
      "  [206.4 228.6 210.2]\n",
      "  [206.  228.6 210.2]\n",
      "  ...\n",
      "  [206.8 228.8 211.4]\n",
      "  [207.  228.  211. ]\n",
      "  [208.2 228.2 210.2]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[208.2 228.2 210.2]\n",
      "  [207.  228.  211. ]\n",
      "  [206.8 228.8 211.4]\n",
      "  ...\n",
      "  [207.4 228.2 209. ]\n",
      "  [207.6 228.  208.8]\n",
      "  [207.6 228.2 208.4]]\n",
      "\n",
      " [[207.6 228.6 210. ]\n",
      "  [207.  228.8 211. ]\n",
      "  [207.6 228.6 211.6]\n",
      "  ...\n",
      "  [207.6 228.  209. ]\n",
      "  [207.6 228.  208.2]\n",
      "  [208.  228.  208.2]]\n",
      "\n",
      " [[207.4 228.6 209. ]\n",
      "  [207.8 228.8 210.2]\n",
      "  [207.8 227.8 209.8]\n",
      "  ...\n",
      "  [207.6 228.  208.8]\n",
      "  [208.  228.  208.2]\n",
      "  [208.  228.  207.4]]]\n",
      "The deviations:\n",
      "[[[82.21338091 41.44683341 77.70559825]\n",
      "  [82.86760525 41.32118101 77.70559825]\n",
      "  [82.86760525 40.85388598 77.70559825]\n",
      "  ...\n",
      "  [82.47035831 43.00418584 78.49942675]\n",
      "  [82.47035831 41.05800775 77.70559825]\n",
      "  [83.26487855 41.44683341 80.0874522 ]]\n",
      "\n",
      " [[82.42426827 41.44683341 77.70559825]\n",
      "  [82.53241787 41.44683341 77.70559825]\n",
      "  [82.64236202 41.32118101 77.70559825]\n",
      "  ...\n",
      "  [83.66217783 41.05800775 74.92823233]\n",
      "  [84.05950273 41.05800775 76.11832894]\n",
      "  [82.86760525 41.44683341 78.10249676]]\n",
      "\n",
      " [[82.53241787 41.44683341 77.70559825]\n",
      "  [82.21338091 41.44683341 77.70559825]\n",
      "  [82.00975552 41.44683341 77.70559825]\n",
      "  ...\n",
      "  [84.45685289 41.05800775 75.32489628]\n",
      "  [84.05950273 42.61455151 76.11832894]\n",
      "  [81.67594505 42.22511101 77.70559825]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[81.67594505 42.22511101 77.70559825]\n",
      "  [84.05950273 42.61455151 76.11832894]\n",
      "  [84.45685289 41.05800775 75.32489628]\n",
      "  ...\n",
      "  [82.75409355 41.19417435 77.03505695]\n",
      "  [82.35678478 41.58365063 76.92957819]\n",
      "  [82.35678478 41.71043035 76.724442  ]]\n",
      "\n",
      " [[82.86760525 41.44683341 78.10249676]\n",
      "  [84.05950273 41.05800775 76.11832894]\n",
      "  [82.86760525 41.44683341 74.92823233]\n",
      "  ...\n",
      "  [82.35678478 41.58365063 77.03505695]\n",
      "  [82.35678478 41.58365063 77.12172197]\n",
      "  [81.56224617 41.58365063 77.12172197]]\n",
      "\n",
      " [[83.26487855 41.44683341 80.0874522 ]\n",
      "  [82.47035831 41.05800775 77.70559825]\n",
      "  [82.47035831 43.00418584 78.49942675]\n",
      "  ...\n",
      "  [82.35678478 41.58365063 76.92957819]\n",
      "  [81.56224617 41.58365063 77.12172197]\n",
      "  [81.56224617 41.58365063 77.71898095]]]\n"
     ]
    }
   ],
   "source": [
    "#2.: calculating the mean and deviation for every color of every pixel\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "# the calculation of average and deviation should be made for each and every pixel and each different color\n",
    "# using the five images, because in case of pattern recognition every color component of every pixel is a different feature\n",
    "pixel_lists=[list(range(128)), list(range(128))]\n",
    "pixels=itertools.product(*pixel_lists)  # this will result in an iterable object, which corresponds to the direct product of the two lists containing indices\n",
    "means=np.zeros((128,128,3)) #preallocation of the matrices containing the mean values and deviations\n",
    "devs=np.zeros((128,128,3))\n",
    "\n",
    "for pixel in pixels: #iterating through the pixels\n",
    "    for color in range(3): # iterating through the channels (R, G, B)\n",
    "        aux_list=[] # auxiliary list, which corresponds to a given pixel and a given color and contains the intensity values for all the five pics\n",
    "        for i in range(5):# iterating through the images\n",
    "            aux_list.append(pics[i][pixel+(color,)])\n",
    "        means[pixel+(color,)]=np.mean(aux_list)\n",
    "        devs[pixel+(color,)]=math.sqrt(np.var(aux_list))\n",
    "print('The average values:')\n",
    "print(means)\n",
    "print('The deviations:')\n",
    "print(devs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standardised data:\n",
      "[array([[[0.59114465, 0.6369606 , 0.57653504],\n",
      "        [0.57199674, 0.64373765, 0.57653504],\n",
      "        [0.57199674, 0.67068283, 0.57653504],\n",
      "        ...,\n",
      "        [0.57232685, 0.63249657, 0.57580038],\n",
      "        [0.57232685, 0.63812156, 0.57653504],\n",
      "        [0.5716696 , 0.6369606 , 0.57437212]],\n",
      "\n",
      "       [[0.58477923, 0.6369606 , 0.57653504],\n",
      "        [0.58158965, 0.6369606 , 0.57653504],\n",
      "        [0.57839586, 0.64373765, 0.57653504],\n",
      "        ...,\n",
      "        [0.57134539, 0.63812156, 0.57922092],\n",
      "        [0.57102408, 0.63812156, 0.57804737],\n",
      "        [0.57199674, 0.6369606 , 0.57616596]],\n",
      "\n",
      "       [[0.58158965, 0.6369606 , 0.57653504],\n",
      "        [0.59114465, 0.6369606 , 0.57653504],\n",
      "        [0.59748989, 0.6369606 , 0.57653504],\n",
      "        ...,\n",
      "        [0.57070561, 0.63812156, 0.57882589],\n",
      "        [0.57102408, 0.63358639, 0.57804737],\n",
      "        [0.57299612, 0.63469342, 0.57653504]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.57299612, 0.63469342, 0.57653504],\n",
      "        [0.57102408, 0.63358639, 0.57804737],\n",
      "        [0.57070561, 0.63812156, 0.57882589],\n",
      "        ...,\n",
      "        [0.57519813, 0.65057743, 0.59713073],\n",
      "        [0.57554457, 0.64929364, 0.60054924],\n",
      "        [0.57554457, 0.64252514, 0.60736838]],\n",
      "\n",
      "       [[0.57199674, 0.6369606 , 0.57616596],\n",
      "        [0.57102408, 0.63812156, 0.57804737],\n",
      "        [0.57199674, 0.6369606 , 0.57922092],\n",
      "        ...,\n",
      "        [0.57554457, 0.64929364, 0.59713073],\n",
      "        [0.57554457, 0.64929364, 0.60683292],\n",
      "        [0.576247  , 0.64929364, 0.60683292]],\n",
      "\n",
      "       [[0.5716696 , 0.6369606 , 0.57437212],\n",
      "        [0.57232685, 0.63812156, 0.57653504],\n",
      "        [0.57232685, 0.63249657, 0.57580038],\n",
      "        ...,\n",
      "        [0.57554457, 0.64929364, 0.60054924],\n",
      "        [0.576247  , 0.64929364, 0.60683292],\n",
      "        [0.576247  , 0.64929364, 0.612463  ]]]), array([[[0.59114465, 0.6369606 , 0.57653504],\n",
      "        [0.57199674, 0.64373765, 0.57653504],\n",
      "        [0.57199674, 0.67068283, 0.57653504],\n",
      "        ...,\n",
      "        [0.57232685, 0.63249657, 0.57580038],\n",
      "        [0.57232685, 0.63812156, 0.57653504],\n",
      "        [0.5716696 , 0.6369606 , 0.57437212]],\n",
      "\n",
      "       [[0.58477923, 0.6369606 , 0.57653504],\n",
      "        [0.58158965, 0.6369606 , 0.57653504],\n",
      "        [0.57839586, 0.64373765, 0.57653504],\n",
      "        ...,\n",
      "        [0.57134539, 0.63812156, 0.57922092],\n",
      "        [0.57102408, 0.63812156, 0.57804737],\n",
      "        [0.57199674, 0.6369606 , 0.57616596]],\n",
      "\n",
      "       [[0.58158965, 0.6369606 , 0.57653504],\n",
      "        [0.59114465, 0.6369606 , 0.57653504],\n",
      "        [0.59748989, 0.6369606 , 0.57653504],\n",
      "        ...,\n",
      "        [0.57070561, 0.63812156, 0.57882589],\n",
      "        [0.57102408, 0.63358639, 0.57804737],\n",
      "        [0.57299612, 0.63469342, 0.57653504]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.57299612, 0.63469342, 0.57653504],\n",
      "        [0.57102408, 0.63358639, 0.57804737],\n",
      "        [0.57070561, 0.63812156, 0.57882589],\n",
      "        ...,\n",
      "        [0.57519813, 0.62630215, 0.53222522],\n",
      "        [0.57554457, 0.62524573, 0.52255584],\n",
      "        [0.57554457, 0.64252514, 0.50309913]],\n",
      "\n",
      "       [[0.57199674, 0.6369606 , 0.57616596],\n",
      "        [0.57102408, 0.63812156, 0.57804737],\n",
      "        [0.57199674, 0.6369606 , 0.57922092],\n",
      "        ...,\n",
      "        [0.57554457, 0.62524573, 0.53222522],\n",
      "        [0.57554457, 0.62524573, 0.5031008 ],\n",
      "        [0.576247  , 0.62524573, 0.5031008 ]],\n",
      "\n",
      "       [[0.5716696 , 0.6369606 , 0.57437212],\n",
      "        [0.57232685, 0.63812156, 0.57653504],\n",
      "        [0.57232685, 0.63249657, 0.57580038],\n",
      "        ...,\n",
      "        [0.57554457, 0.62524573, 0.52255584],\n",
      "        [0.576247  , 0.62524573, 0.5031008 ],\n",
      "        [0.576247  , 0.62524573, 0.4837943 ]]]), array([[[0.28705789, 0.03377821, 0.2548079 ],\n",
      "        [0.2703107 , 0.03872106, 0.2548079 ],\n",
      "        [0.2703107 , 0.05874594, 0.2548079 ],\n",
      "        ...,\n",
      "        [0.26918763, 0.05115781, 0.25732672],\n",
      "        [0.26918763, 0.02922694, 0.2548079 ],\n",
      "        [0.27142296, 0.03377821, 0.26221336]],\n",
      "\n",
      "       [[0.2814705 , 0.03377821, 0.2548079 ],\n",
      "        [0.27867837, 0.03377821, 0.2548079 ],\n",
      "        [0.27588756, 0.03872106, 0.2548079 ],\n",
      "        ...,\n",
      "        [0.27252458, 0.02922694, 0.24556832],\n",
      "        [0.2736157 , 0.02922694, 0.24961137],\n",
      "        [0.2703107 , 0.03377821, 0.25607376]],\n",
      "\n",
      "       [[0.27867837, 0.03377821, 0.2548079 ],\n",
      "        [0.28705789, 0.03377821, 0.2548079 ],\n",
      "        [0.29264811, 0.03377821, 0.2548079 ],\n",
      "        ...,\n",
      "        [0.27469648, 0.02922694, 0.24693031],\n",
      "        [0.2736157 , 0.04693233, 0.24961137],\n",
      "        [0.26690845, 0.04262866, 0.2548079 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.26690845, 0.04262866, 0.2548079 ],\n",
      "        [0.2736157 , 0.04693233, 0.24961137],\n",
      "        [0.27469648, 0.02922694, 0.24693031],\n",
      "        ...,\n",
      "        [0.27309827, 0.0436955 , 0.27260316],\n",
      "        [0.27198731, 0.04809583, 0.27557671],\n",
      "        [0.27198731, 0.04315467, 0.28152697]],\n",
      "\n",
      "       [[0.2703107 , 0.03377821, 0.25607376],\n",
      "        [0.2736157 , 0.02922694, 0.24961137],\n",
      "        [0.2703107 , 0.03377821, 0.24556832],\n",
      "        ...,\n",
      "        [0.27198731, 0.04809583, 0.27260316],\n",
      "        [0.27198731, 0.04809583, 0.28267004],\n",
      "        [0.26973264, 0.04809583, 0.28267004]],\n",
      "\n",
      "       [[0.27142296, 0.03377821, 0.26221336],\n",
      "        [0.26918763, 0.02922694, 0.2548079 ],\n",
      "        [0.26918763, 0.05115781, 0.25732672],\n",
      "        ...,\n",
      "        [0.27198731, 0.04809583, 0.27557671],\n",
      "        [0.26973264, 0.04809583, 0.28267004],\n",
      "        [0.26973264, 0.04809583, 0.29079125]]]), array([[[0.51816383, 0.6369606 , 0.57653504],\n",
      "        [0.57199674, 0.61953699, 0.57653504],\n",
      "        [0.57199674, 0.54829545, 0.57653504],\n",
      "        ...,\n",
      "        [0.57232685, 0.63249657, 0.57580038],\n",
      "        [0.57232685, 0.63812156, 0.57653504],\n",
      "        [0.5716696 , 0.6369606 , 0.57437212]],\n",
      "\n",
      "       [[0.53624983, 0.6369606 , 0.57653504],\n",
      "        [0.5452403 , 0.6369606 , 0.57653504],\n",
      "        [0.5541952 , 0.61953699, 0.57653504],\n",
      "        ...,\n",
      "        [0.57134539, 0.63812156, 0.57922092],\n",
      "        [0.57102408, 0.63812156, 0.57804737],\n",
      "        [0.57199674, 0.6369606 , 0.57616596]],\n",
      "\n",
      "       [[0.5452403 , 0.6369606 , 0.57653504],\n",
      "        [0.51816383, 0.6369606 , 0.57653504],\n",
      "        [0.49994052, 0.6369606 , 0.57653504],\n",
      "        ...,\n",
      "        [0.57070561, 0.63812156, 0.57882589],\n",
      "        [0.57102408, 0.63358639, 0.57804737],\n",
      "        [0.57299612, 0.63469342, 0.57653504]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.57299612, 0.63469342, 0.57653504],\n",
      "        [0.57102408, 0.63358639, 0.57804737],\n",
      "        [0.57070561, 0.63812156, 0.57882589],\n",
      "        ...,\n",
      "        [0.56311414, 0.62630215, 0.58414963],\n",
      "        [0.56340228, 0.62524573, 0.58755034],\n",
      "        [0.56340228, 0.61855032, 0.59433472]],\n",
      "\n",
      "       [[0.57199674, 0.6369606 , 0.57616596],\n",
      "        [0.57102408, 0.63812156, 0.57804737],\n",
      "        [0.57199674, 0.6369606 , 0.57922092],\n",
      "        ...,\n",
      "        [0.56340228, 0.62524573, 0.58414963],\n",
      "        [0.56340228, 0.62524573, 0.59386641],\n",
      "        [0.56398643, 0.62524573, 0.59386641]],\n",
      "\n",
      "       [[0.5716696 , 0.6369606 , 0.57437212],\n",
      "        [0.57232685, 0.63812156, 0.57653504],\n",
      "        [0.57232685, 0.63249657, 0.57580038],\n",
      "        ...,\n",
      "        [0.56340228, 0.62524573, 0.58755034],\n",
      "        [0.56398643, 0.62524573, 0.59386641],\n",
      "        [0.56398643, 0.62524573, 0.59959613]]]), array([[[-1.98751101, -1.94466002, -1.98441301],\n",
      "        [-1.98630091, -1.94573335, -1.98441301],\n",
      "        [-1.98630091, -1.94840706, -1.98441301],\n",
      "        ...,\n",
      "        [-1.98616816, -1.94864752, -1.98472787],\n",
      "        [-1.98616816, -1.94359163, -1.98441301],\n",
      "        [-1.98643177, -1.94466002, -1.98532973]],\n",
      "\n",
      "       [[-1.98727879, -1.94466002, -1.98441301],\n",
      "        [-1.98709797, -1.94466002, -1.98441301],\n",
      "        [-1.98687448, -1.94573335, -1.98441301],\n",
      "        ...,\n",
      "        [-1.98656076, -1.94359163, -1.98323109],\n",
      "        [-1.98668794, -1.94359163, -1.98375348],\n",
      "        [-1.98630091, -1.94466002, -1.98457164]],\n",
      "\n",
      "       [[-1.98709797, -1.94466002, -1.98441301],\n",
      "        [-1.98751101, -1.94466002, -1.98441301],\n",
      "        [-1.98756842, -1.94466002, -1.98441301],\n",
      "        ...,\n",
      "        [-1.98681332, -1.94359163, -1.98340797],\n",
      "        [-1.98668794, -1.94769151, -1.98375348],\n",
      "        [-1.98589683, -1.94670891, -1.98441301]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-1.98589683, -1.94670891, -1.98441301],\n",
      "        [-1.98668794, -1.94769151, -1.98375348],\n",
      "        [-1.98681332, -1.94359163, -1.98340797],\n",
      "        ...,\n",
      "        [-1.98660867, -1.94687723, -1.98610874],\n",
      "        [-1.98647871, -1.94788093, -1.98623213],\n",
      "        [-1.98647871, -1.94675527, -1.98632921]],\n",
      "\n",
      "       [[-1.98630091, -1.94466002, -1.98457164],\n",
      "        [-1.98668794, -1.94359163, -1.98375348],\n",
      "        [-1.98630091, -1.94466002, -1.98323109],\n",
      "        ...,\n",
      "        [-1.98647871, -1.94788093, -1.98610874],\n",
      "        [-1.98647871, -1.94788093, -1.98647017],\n",
      "        [-1.98621308, -1.94788093, -1.98647017]],\n",
      "\n",
      "       [[-1.98643177, -1.94466002, -1.98532973],\n",
      "        [-1.98616816, -1.94359163, -1.98441301],\n",
      "        [-1.98616816, -1.94864752, -1.98472787],\n",
      "        ...,\n",
      "        [-1.98647871, -1.94788093, -1.98623213],\n",
      "        [-1.98621308, -1.94788093, -1.98647017],\n",
      "        [-1.98621308, -1.94788093, -1.98664468]]])]\n",
      "========================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average values after standardisation:\n",
      "[[[-8.88178420e-17  1.33226763e-16  1.33226763e-16]\n",
      "  [ 1.33226763e-16 -1.77635684e-16  1.33226763e-16]\n",
      "  [ 1.33226763e-16  1.33226763e-16  1.33226763e-16]\n",
      "  ...\n",
      "  [-8.88178420e-17 -2.66453526e-16 -1.33226763e-16]\n",
      "  [-8.88178420e-17 -2.22044605e-16  1.33226763e-16]\n",
      "  [-1.33226763e-16  1.33226763e-16 -4.44089210e-17]]\n",
      "\n",
      " [[-8.88178420e-17  1.33226763e-16  1.33226763e-16]\n",
      "  [-4.44089210e-17  1.33226763e-16  1.33226763e-16]\n",
      "  [ 1.33226763e-16 -1.77635684e-16  1.33226763e-16]\n",
      "  ...\n",
      "  [ 8.88178420e-17 -2.22044605e-16  8.88178420e-17]\n",
      "  [ 0.00000000e+00 -2.22044605e-16  0.00000000e+00]\n",
      "  [ 1.33226763e-16  1.33226763e-16 -4.44089210e-17]]\n",
      "\n",
      " [[-4.44089210e-17  1.33226763e-16  1.33226763e-16]\n",
      "  [-8.88178420e-17  1.33226763e-16  1.33226763e-16]\n",
      "  [-4.44089210e-17  1.33226763e-16  1.33226763e-16]\n",
      "  ...\n",
      "  [-1.33226763e-16 -2.22044605e-16 -8.88178420e-17]\n",
      "  [ 0.00000000e+00 -4.44089210e-17  0.00000000e+00]\n",
      "  [ 8.88178420e-17  3.10862447e-16  1.33226763e-16]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 8.88178420e-17  3.10862447e-16  1.33226763e-16]\n",
      "  [ 0.00000000e+00 -4.44089210e-17  0.00000000e+00]\n",
      "  [-1.33226763e-16 -2.22044605e-16 -8.88178420e-17]\n",
      "  ...\n",
      "  [-8.88178420e-17  2.66453526e-16  4.44089210e-17]\n",
      "  [ 8.88178420e-17  0.00000000e+00 -8.88178420e-17]\n",
      "  [ 8.88178420e-17  2.66453526e-16 -4.44089210e-17]]\n",
      "\n",
      " [[ 1.33226763e-16  1.33226763e-16 -4.44089210e-17]\n",
      "  [ 0.00000000e+00 -2.22044605e-16  0.00000000e+00]\n",
      "  [ 1.33226763e-16  1.33226763e-16  8.88178420e-17]\n",
      "  ...\n",
      "  [ 8.88178420e-17  0.00000000e+00  4.44089210e-17]\n",
      "  [ 8.88178420e-17  0.00000000e+00  1.33226763e-16]\n",
      "  [ 0.00000000e+00  0.00000000e+00  1.33226763e-16]]\n",
      "\n",
      " [[-1.33226763e-16  1.33226763e-16 -4.44089210e-17]\n",
      "  [-8.88178420e-17 -2.22044605e-16  1.33226763e-16]\n",
      "  [-8.88178420e-17 -2.66453526e-16 -1.33226763e-16]\n",
      "  ...\n",
      "  [ 8.88178420e-17  0.00000000e+00 -8.88178420e-17]\n",
      "  [ 0.00000000e+00  0.00000000e+00  1.33226763e-16]\n",
      "  [ 0.00000000e+00  0.00000000e+00 -8.88178420e-17]]]\n",
      "The deviations after standardisation:\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "#2.: standardising the data\n",
    "pics_std=[] # standardised data will be stored here, the tensors corresponding to each pic will be assigned to the list elements\n",
    "for i in range(5):\n",
    "    pics[i]=np.array(pics[i])\n",
    "    std=(pics[i]-means)/devs\n",
    "    pics_std.append(std)\n",
    "print('The standardised data:')\n",
    "print(pics_std)\n",
    "print('========================================================')\n",
    "means_std=np.zeros((128,128,3))\n",
    "devs_std=np.zeros((128,128,3))\n",
    "\n",
    "pixel_lists2=[list(range(128)), list(range(128))]\n",
    "pixels2=itertools.product(*pixel_lists2)\n",
    "# checking the mean values and deviations\n",
    "for pix in pixels2: #iterating through the pixels\n",
    "    for col in range(3): # iterating through the channels (R, G, B)\n",
    "        aux_list=[]\n",
    "        for i in range(5):# iterating through the images\n",
    "            aux_list.append(pics_std[i][pix+(col,)])\n",
    "        means_std[pix+(col,)]=np.mean(aux_list)\n",
    "        devs_std[pix+(col,)]=math.sqrt(np.var(aux_list))\n",
    "print('The average values after standardisation:')\n",
    "print(means_std)\n",
    "print('The deviations after standardisation:')\n",
    "print(devs_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The future of deep learning \n",
      " [if IE]>\n",
      "                <script src=\"http://html5shiv.googlecode.com/svn/trunk/html5.js\"></script><![endif] \n",
      " [if lte IE 7]>\n",
      "                <link rel=\"stylesheet\" type=\"text/css\" media=\"all\" href=\"//blog.keras.io/css/ie.css\"/>\n",
      "                <script src=\"//blog.keras.io/js/IE8.js\" type=\"text/javascript\"></script><![endif] \n",
      " [if lt IE 7]>\n",
      "                <link rel=\"stylesheet\" type=\"text/css\" media=\"all\" href=\"//blog.keras.io/css/ie6.css\"/><![endif] \n",
      " \n",
      " \n",
      " The Keras Blog  \n",
      " \n",
      " Keras  is a Deep Learning library for Python, that is simple, modular, and extensible.\n",
      "                 \n",
      " Archives \n",
      " \n",
      " Github \n",
      " \n",
      " \n",
      " Documentation \n",
      " \n",
      " \n",
      " Google Group \n",
      " \n",
      "  /#banner  \n",
      " \n",
      " \n",
      " The future of deep learning \n",
      " \n",
      " \n",
      " \n",
      "                Tue 18 July 2017\n",
      "         \n",
      " \n",
      "                By  Francois Chollet \n",
      " \n",
      " In  Essays .  \n",
      " This post is adapted from Section 3 of Chapter 9 of my book,  Deep Learning with Python  (Manning Publications).  It is part of a series of two posts on the current limitations of deep learning, and its future. \n",
      "You can read the first part here:  The Limitations of Deep Learning . Given what we know of how deep nets work, of their limitations, and of the current state of the research landscape, \n",
      "can we predict where things are headed in the medium term? Here are some purely personal thoughts. Note that I don't have a crystal ball, \n",
      "so a lot of what I anticipate might fail to become reality. This is a completely speculative post. \n",
      "I am sharing these predictions not because I expect them to be proven \n",
      "completely right in the future, but because they are interesting and actionable in the present. At a high-level, the main directions in which I see promise are: \n",
      " Models closer to general-purpose computer programs, built on top of far richer primitives than our current differentiable layers—this \n",
      "is how we will get to  reasoning  and  abstraction , the fundamental weakness of current models. \n",
      " New forms of learning that make the above possible—allowing models to move away from just differentiable transforms. \n",
      " Models that require less involvement from human engineers—it shouldn't be your job to tune knobs endlessly. \n",
      " Greater, systematic reuse of previously learned features and architectures; meta-learning systems based on reusable and modular program \n",
      "subroutines. \n",
      " Additionally, do note that these considerations are not specific to the sort of supervised learning that has been the bread and butter of \n",
      "deep learning so far—rather, they are applicable to any form of machine learning, including unsupervised, self-supervised, and \n",
      "reinforcement learning. It is not fundamentally important where your labels come from or what your training loop looks like; \n",
      "these different branches of machine learning are just different facets of a same construct. Let's dive in. Models as programs As we noted in our previous post, a necessary transformational development that we can expect in the field of machine learning is a move away \n",
      "from models that perform purely  pattern recognition  and can only achieve  local generalization , towards models capable of  abstraction  and \n",
      " reasoning , that can achieve  extreme generalization . Current AI programs that are capable of basic forms of reasoning are all hard-coded \n",
      "by human programmers: for instance, software that relies on search algorithms, graph manipulation, formal logic. \n",
      "In DeepMind's AlphaGo, for example, most of the \"intelligence\" on display is designed and hard-coded by expert programmers (e.g. Monte-Carlo tree search); \n",
      "learning from data only happens in specialized submodules (value networks and policy networks). \n",
      "But in the future, such AI systems may well be fully learned, with no human involvement. What could be the path to make this happen? Consider a well-known type of network: RNNs. \n",
      "Importantly, RNNs have slightly less limitations than feedforward networks. \n",
      "That is because RNNs are a bit more than a mere geometric transformation: they are geometric transformations  repeatedly applied inside a  for  \n",
      "loop . The temporal  for  loop is itself hard-coded by human developers: it is a built-in assumption of the network. Naturally, RNNs are \n",
      "still extremely limited in what they can represent, primarily because each step they perform is still just a differentiable geometric \n",
      "transformation, and the way they carry information from step to step is via points in a continuous geometric space (state vectors). Now, \n",
      "imagine neural networks that would be \"augmented\" in a similar way with programming primitives such as  for  loops—but not just a single \n",
      "hard-coded  for  loop with a hard-coded geometric memory, rather, a large set of programming primitives that the model would be free to manipulate to expand its \n",
      "processing function, such as  if  branches,  while  statements, variable creation, disk storage for long-term memory, \n",
      "sorting operators, advanced datastructures like lists, graphs, and hashtables, and many more. \n",
      "The space of programs that such a network could represent would be far broader than what can be represented with current deep learning models, \n",
      "and some of these programs could achieve superior generalization power. In a word, we will move away from having on one hand \"hard-coded algorithmic intelligence\" (handcrafted software) and on the other hand \n",
      "\"learned geometric intelligence\" (deep learning). We will have instead a blend of formal algorithmic modules that provide  reasoning and \n",
      "abstraction  capabilities, and geometric modules that provide  informal intuition and pattern recognition  capabilities. The whole system would be \n",
      "learned with little or no human involvement. A related subfield of AI that I think may be about to take off in a big way is that of  program synthesis , in particular neural program \n",
      "synthesis. Program synthesis consists in automatically generating simple programs, by using a search algorithm (possibly genetic search, as \n",
      "in genetic programming) to explore a large space of possible programs. The search stops when a program is found that matches the required \n",
      "specifications, often provided as a set of input-output pairs. As you can see, is it highly reminiscent of machine learning: given \n",
      "\"training data\" provided as input-output pairs, we find a \"program\" that matches inputs to outputs and can generalize to new inputs. The \n",
      "difference is that instead of learning parameter values in a hard-coded program (a neural network), \n",
      "we generate  source code  via a discrete search process. I would definitely expect this subfield to see a wave of renewed interest in the next few years. In particular, I would expect the \n",
      "emergence of a crossover subfield in-between deep learning and program synthesis, where we would not quite be generating programs in a \n",
      "general-purpose language, but rather, where we would be generating neural networks (geometric data processing flows)  augmented  with a \n",
      "rich set of algorithmic primitives, such as  for  loops—and many others. This should be far more tractable and useful than directly \n",
      "generating source code, and it would dramatically expand the scope of problems that can be solved with machine learning—the space of programs \n",
      "that we can generate automatically given appropriate training data. A blend of symbolic AI and geometric AI. \n",
      "Contemporary RNNs can be seen as a prehistoric ancestor to such hybrid algorithmic-geometric models. Figure:   A learned program relying on both geometric primitives (pattern recognition, intuition) and algorithmic primitives (reasoning, search, memory). Beyond backpropagation and differentiable layers If machine learning models become more like programs, then they will mostly no longer be differentiable—certainly, these programs will \n",
      "still leverage continuous geometric layers as subroutines, which will be differentiable, but the model as a whole would not be. As a \n",
      "result, using backpropagation to adjust weight values in a fixed, hard-coded network, cannot be the method of choice for training models in the \n",
      "future—at least, it cannot be the whole story. We need to figure out to train non-differentiable systems efficiently. Current approaches \n",
      "include genetic algorithms, \"evolution strategies\", certain reinforcement learning methods, \n",
      "and ADMM (alternating direction method of multipliers). \n",
      "Naturally, gradient descent is not going anywhere—gradient information will always be useful for optimizing differentiable parametric functions. But our models \n",
      "will certainly become increasingly more ambitious than mere differentiable parametric functions, \n",
      "and thus their automatic development (the \"learning\" in \"machine learning\") will require more than backpropagation. Besides, backpropagation is end-to-end, which is a great thing for learning good chained transformations, but is rather computationally \n",
      "inefficient since it doesn't fully leverage the modularity of deep networks. To make something more efficient, there is one universal \n",
      "recipe: introduce modularity and hierarchy. So we can make backprop itself more efficient by introducing decoupled training modules with some \n",
      "synchronization mechanism between them, organized in a hierarchical fashion. This strategy is somewhat reflected in DeepMind's recent work \n",
      "on \"synthetic gradients\". I would expect more more work along these lines in the near future. One can imagine a future where models that would be globally non-differentiable (but would feature differentiable parts) would be \n",
      "trained—grown—using an efficient search process that would not leverage gradients, while the differentiable parts would be trained even faster \n",
      "by taking advantage of gradients using some more efficient version of backpropagation. Automated machine learning In the future, model architectures will be learned, rather than handcrafted by engineer-artisans. Learning architectures automatically goes \n",
      "hand in hand with the use of richer sets of primitives and program-like machine learning models. Currently, most of the job of a deep learning engineer consists in munging data with Python scripts, then lengthily tuning the architecture \n",
      "and hyperparameters of a deep network to get a working model—or even, to get to a state-of-the-art model, if the engineer is so \n",
      "ambitious. Needless to say, that is not an optimal setup. But AI can help there too. Unfortunately, the data munging part is tough to \n",
      "automate, since it often requires domain knowledge as well as a clear high-level understanding of what the engineer wants to achieve. \n",
      "Hyperparameter tuning, however, is a simple search procedure, and we already know what the engineer wants to achieve in this case: it is \n",
      "defined by the loss function of the network being tuned. It is already common practice to set up basic \"AutoML\" systems that will take care \n",
      "of most of the model knob tuning. I even set up my own years ago to win Kaggle competitions. At the most basic level, such a system would simply tune the number of layers in a stack, their order, and the number of units or filters \n",
      "in each layer. This is commonly done with libraries such as Hyperopt, which we discussed in Chapter 7 \n",
      "(Note: of  Deep Learning with Python ). \n",
      "But we can also be far more \n",
      "ambitious, and attempt to learn an appropriate architecture from scratch, with as few constraints as possible. This is possible via \n",
      "reinforcement learning, for instance, or genetic algorithms. Another important AutoML direction is to learn model architecture jointly with model weights. Because training a new model from scratch \n",
      "every time we try a slightly different architecture is tremendously inefficient, a truly powerful AutoML system would manage to evolve \n",
      "architectures at the same time as the features of the model are being tuned via backprop on the training data, thus eliminating all computational redundancy. \n",
      "Such approaches are already starting to emerge as I am writing these lines. When this starts happening, the jobs of machine learning engineers will not disappear—rather, engineers will move higher up the value creation chain. \n",
      "They will start putting a lot more effort into crafting complex loss functions that truly reflect business goals, \n",
      "and understanding deeply how their models impact the digital ecosystems in which they are deployed \n",
      "(e.g. the users that consume the model's predictions and generate the model's training data)\n",
      "—problems that currently only the largest company can afford to consider. Lifelong learning and modular subroutine reuse If models get more complex and are built on top of richer algorithmic primitives, then this increased complexity will require higher \n",
      "reuse between tasks, rather than training a new model from scratch every time we have a new task or a new dataset. Indeed, a lot datasets \n",
      "would not contain enough information to develop a new complex model from scratch, and it will become necessary to leverage information \n",
      "coming from previously encountered datasets. Much like you don't learn English from scratch every time you open a new book—that would be \n",
      "impossible. Besides, training models from scratch on every new task is very inefficient due to the large overlap between the current tasks and \n",
      "previously encountered tasks. Additionally, a remarkable observation that has been made repeatedly in recent years is that training a  same  model to do several loosely \n",
      "connected tasks at the same time results in a model that is  better at each task . For instance, training a same neural machine translation \n",
      "model to cover both English-to-German translation and French-to-Italian translation will result in a model that is better at each language \n",
      "pair. Training an image classification model jointly with an image segmentation model, sharing the same convolutional base, results in a \n",
      "model that is better at both tasks. And so on. This is fairly intuitive: there is always  some  information overlap between these seemingly \n",
      "disconnected tasks, and the joint model has thus access to a greater amount of information about each individual task than a model trained \n",
      "on that specific task only. What we currently do along the lines of model reuse across tasks is to leverage pre-trained weights for models that perform common \n",
      "functions, like visual feature extraction. You saw this in action in Chapter 5. In the future, I would expect a generalized version of this \n",
      "to be commonplace: we would not only leverage previously learned features (submodel weights), but also model architectures and training \n",
      "procedures. As models become more like programs, we would start reusing  program subroutines , like the functions and classes found in \n",
      "human programming languages. Think of the process of software development today: once an engineer solves a specific problem (HTTP queries in Python, for instance), they \n",
      "will package it as an abstract and reusable library. Engineers that face a similar problem in the future can simply search for existing \n",
      "libraries, download one and use it in their own project. In a similar way, in the future, meta-learning systems will be able to assemble \n",
      "new programs by sifting through a global library of high-level reusable blocks. When the system would find itself developing similar \n",
      "program subroutines for several different tasks, if would come up with an \"abstract\", reusable version of the subroutine and would store it \n",
      "in the global library. Such a process would implement the capability for  abstraction , a necessary component for achieving \"extreme \n",
      "generalization\": a subroutine that is found to be useful across different tasks and domains can be said to \"abstract\" some aspect of problem-solving. \n",
      "This definition of \"abstraction\" is similar to the notion of abstraction in software engineering. \n",
      "These subroutines could be either geometric (deep learning modules with pre-trained representations) \n",
      "or algorithmic (closer to the libraries that contemporary software engineers manipulate). Figure:   A meta-learner capable of quickly developing task-specific models using reusable primitives (both algorithmic and geometric), thus achieving \"extreme generalization\". In summary: the long-term vision In short, here is my long-term vision for machine learning: \n",
      " Models will be more like programs, and will have capabilities that go far beyond the continuous geometric transformations of the input \n",
      "data that we currently work with. These programs will arguably be much closer to the abstract mental models that humans maintain about their \n",
      "surroundings and themselves, and they will be capable of stronger generalization due to their rich algorithmic nature. \n",
      " In particular, models will blend  algorithmic modules  providing formal reasoning, search, and abstraction capabilities, with  geometric modules  \n",
      "providing informal intuition and pattern recognition capabilities. \n",
      "AlphaGo (a system that required a lot of manual software engineering and human-made design decisions) \n",
      "provides an early example of what such a blend between symbolic and geometric AI could look like. \n",
      " They will be  grown  automatically rather than handcrafted by human engineers, using modular parts stored in a global library of reusable \n",
      "subroutines—a library evolved by learning high-performing models on thousands of previous tasks and datasets. As common problem-solving \n",
      "patterns are identified by the meta-learning system, they would be turned into a reusable subroutine—much like functions and classes in \n",
      "contemporary software engineering—and added to the global library. This achieves the capability for  abstraction . \n",
      " This global library and associated model-growing system will be able to achieve some form of human-like \"extreme generalization\": given a \n",
      "new task, a new situation, the system would be able to assemble a new working model appropriate for the task using very little data, thanks \n",
      "to 1) rich program-like primitives that generalize well and 2) extensive experience with similar tasks. \n",
      "In the same way that humans can learn to play a complex new video \n",
      "game using very little play time because they have experience with many previous games, and because the models derived from this previous \n",
      "experience are abstract and program-like, rather than a basic mapping between stimuli and action. \n",
      " As such, this perpetually-learning model-growing system could be interpreted as an AGI—an Artificial General Intelligence. But don't \n",
      "expect any singularitarian robot apocalypse to ensue: that's a pure fantasy, coming from a long series of profound misunderstandings of \n",
      "both intelligence and technology. This critique, however, does not belong here. \n",
      " @fchollet , May 2017 \n",
      " \n",
      "                Powered by  pelican , which takes great advantages of  python .\n",
      "                  /#about  \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# 3.: retrieving text from html webpage\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://blog.keras.io/the-future-of-deep-learning.html\"\n",
    "html = urllib.request.urlopen(url).read() # this will read the html code as a bytearray\n",
    "soup = BeautifulSoup(html, 'html.parser') # beatifulsoup object has to be created in order to be able to process the html code\n",
    "\n",
    "text = soup.find_all(text=True) # finding all the contents which correspond to text property\n",
    "\n",
    "output = ''\n",
    "blacklist = [   # these tags are unwanted for us\n",
    "    '[document]',\n",
    "    'noscript',\n",
    "    'header',\n",
    "    'html',\n",
    "    'meta',\n",
    "    'head', \n",
    "    'input',\n",
    "    'script',\n",
    "    '!--[if IE]'\n",
    "    '!--[if lte IE 7]'\n",
    "]\n",
    "\n",
    "for t in text:\n",
    "    if t.parent.name not in blacklist: # filtering the unwanted parentnames\n",
    "        output += '{} '.format(t)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['std', 'text']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "#3. histogram \n",
    "%pylab\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "char_list = list(output) # convert input to list of chars\n",
    "to_remove=['.', ',', '\"', '/', '(', ')', ':', '-', \"\"\"'\"\"\", '=', '<', '>', '[', ']', ';', '!', '#', '?', '@', \n",
    "            '0', '1', '2', '3', '5', '6', '7', '8', '9', '_'] # these caracters \n",
    "for c in output:\n",
    "    if c in to_remove:\n",
    "        char_list.remove(c)\n",
    "# create a dataframe where each char is one row\n",
    "df = pd.DataFrame({'chars': char_list})\n",
    "# drop all the space characters\n",
    "df = df[df.chars != ' ']\n",
    "# add a column for aggregation later\n",
    "df['num'] = 1\n",
    "# group rows by character type, count the occurences in each group\n",
    "\n",
    "df = df.groupby('chars').sum()\n",
    "plt.bar(df.index, df.num, width=0.5, color='g')\n",
    "plt.title('Numbers of incidence of letters')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
